{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIzg7l8PO3Kv"
   },
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 711,
     "status": "ok",
     "timestamp": 1607487808354,
     "user": {
      "displayName": "Shivin Shetty",
      "photoUrl": "",
      "userId": "17836269469119195262"
     },
     "user_tz": 300
    },
    "id": "7ADl1YBvO3Kw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils import data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import *\n",
    "import gtn\n",
    "import soundfile as sf\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 557,
     "status": "ok",
     "timestamp": 1607487809154,
     "user": {
      "displayName": "Shivin Shetty",
      "photoUrl": "",
      "userId": "17836269469119195262"
     },
     "user_tz": 300
    },
    "id": "WWvwS5ILO3Kw"
   },
   "outputs": [],
   "source": [
    "etc_path = \"/home/ubuntu/project/an4/etc/\"\n",
    "wav_path = \"/home/ubuntu/project/an4/wav/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 398,
     "status": "ok",
     "timestamp": 1607487809431,
     "user": {
      "displayName": "Shivin Shetty",
      "photoUrl": "",
      "userId": "17836269469119195262"
     },
     "user_tz": 300
    },
    "id": "hDBhymFdO3Kx"
   },
   "outputs": [],
   "source": [
    "train_fileids_path = etc_path + \"an4_train.fileids\"\n",
    "train_trans_path = etc_path + \"an4_train.transcription\"\n",
    "\n",
    "test_fileids_path = etc_path + \"an4_test.fileids\"\n",
    "test_trans_path = etc_path + \"an4_test.transcription\"\n",
    "\n",
    "phones_path = etc_path + \"an4.phone\"\n",
    "filler_path = etc_path + \"an4.filler\"\n",
    "dict_path = etc_path + \"an4.dic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 383,
     "status": "ok",
     "timestamp": 1607487810621,
     "user": {
      "displayName": "Shivin Shetty",
      "photoUrl": "",
      "userId": "17836269469119195262"
     },
     "user_tz": 300
    },
    "id": "KJgwuRRoO3Kx",
    "outputId": "1cd37f07-d8ee-43e9-a724-f3dbc09924b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'B', 'CH', 'D', 'EH', 'ER', 'EY', 'F', 'G', 'HH', 'IH', 'IY', 'JH', 'K', 'L', 'M', 'N', 'OW', 'P', 'R', 'S', 'SIL', 'T', 'TH', 'UW', 'V', 'W', 'Y', 'Z']\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "with open(phones_path, 'r') as f:\n",
    "    phones = f.read().splitlines()\n",
    "\n",
    "print(phones)\n",
    "print(len(phones))\n",
    "phones_plus_one = ['#'] + phones\n",
    "label_to_phone = dict(enumerate(phones_plus_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 408,
     "status": "ok",
     "timestamp": 1607487811214,
     "user": {
      "displayName": "Shivin Shetty",
      "photoUrl": "",
      "userId": "17836269469119195262"
     },
     "user_tz": 300
    },
    "id": "9DFczlLiO3Kx",
    "outputId": "cd345ac4-e8e3-442d-a1fe-a3c61e59ef84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "num_phones = len(phones_plus_one)\n",
    "print(num_phones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1607487813259,
     "user": {
      "displayName": "Shivin Shetty",
      "photoUrl": "",
      "userId": "17836269469119195262"
     },
     "user_tz": 300
    },
    "id": "YtygyuDWO3Ky",
    "outputId": "237f35bc-dc3f-4738-ce76-a051f874e5af"
   },
   "outputs": [],
   "source": [
    "word_to_phones = {}\n",
    "phones_to_words = {}\n",
    "\n",
    "for d in [dict_path, filler_path]:\n",
    "    with open(d, 'r') as f:\n",
    "        mappings = f.read().splitlines()\n",
    "        for pair in mappings:\n",
    "            items = pair.split()\n",
    "            word = items[0]\n",
    "            transc = tuple(phones.index(i)+1 for i in items[1:])\n",
    "\n",
    "            if word.endswith(\")\"):\n",
    "                word = word[:-3]\n",
    "                word_to_phones[word].append(transc)\n",
    "            else:\n",
    "                word_to_phones[word] = [transc]\n",
    "\n",
    "            if transc not in phones_to_words:\n",
    "                phones_to_words[transc] = []\n",
    "            phones_to_words[transc].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1607487814677,
     "user": {
      "displayName": "Shivin Shetty",
      "photoUrl": "",
      "userId": "17836269469119195262"
     },
     "user_tz": 300
    },
    "id": "fr48VzLNO3Ky"
   },
   "outputs": [],
   "source": [
    "# word_graphs = {}\n",
    "def make_word_graph(word, calc_grad=True, blank=0):\n",
    "    pron = word_to_phones[word]\n",
    "    G = None\n",
    "    for pidx in range(len(pron)):\n",
    "        pronunciation = pron[pidx]\n",
    "        g = gtn.Graph(calc_grad)\n",
    "        u = len(pronunciation) * 2 + 1\n",
    "        for l in range(u):\n",
    "            idx = (l-1) // 2\n",
    "            is_start = (l == 0)\n",
    "            is_accept = (l == u-1) or (l == u-2)\n",
    "            g.add_node(is_start, is_accept)\n",
    "            label = pronunciation[idx] if l % 2 else blank\n",
    "            g.add_arc(l, l, label, label)\n",
    "            if l > 0:\n",
    "                g.add_arc(l-1, l, label, label)\n",
    "            if (l % 2) and (l > 1) and label != pronunciation[idx-1]: # not a repetition\n",
    "                g.add_arc(l-2, l, label, label)\n",
    "        \n",
    "        if pidx == 0:\n",
    "            G = g\n",
    "        else:\n",
    "            G = gtn.union((G, g))\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rhsYl689O3K0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RUBOUT', 'G', 'M', 'E', 'F', 'THREE', 'NINE']\n",
      "['ERASE', 'C', 'Q', 'Q', 'F', 'SEVEN']\n",
      "['B', 'A', 'O', 'Z', 'FIVE', 'THREE']\n",
      "['GO']\n",
      "['RUBOUT', 'N', 'I', 'M', 'N', 'ONE']\n",
      "['W', 'O', 'O', 'D']\n",
      "['C', 'I', 'N', 'D', 'Y']\n",
      "['ONE', 'THREE', 'SEVEN']\n",
      "['M', 'E', 'L', 'V', 'I', 'N']\n",
      "['P', 'L', 'E', 'A', 'S', 'A', 'N', 'T', 'H', 'I', 'L', 'L', 'S']\n",
      "['ONE', 'FIVE', 'TWO', 'THREE', 'SIX']\n",
      "['SIX', 'FIVE', 'FIVE', 'EIGHT', 'SEVEN', 'FOUR', 'ZERO']\n",
      "['ELEVEN', 'TWENTY', 'SEVEN', 'FIFTY', 'SEVEN']\n",
      "['NO']\n",
      "['ENTER', 'NINE', 'ONE', 'SIX', 'NINE']\n",
      "['ENTER', 'EIGHT', 'NINETY', 'SEVEN']\n",
      "['J', 'P', 'E', 'G', 'FOUR']\n",
      "['ERASE', 'X', 'A', 'G', 'N', 'A', 'SIX', 'THIRTY', 'FIVE']\n",
      "['P', 'A', 'T', 'T', 'E', 'R', 'S', 'O', 'N']\n",
      "['J', 'A', 'N', 'E', 'T']\n",
      "['ONE', 'FIFTY']\n",
      "['S', 'P', 'E', 'E', 'R']\n",
      "['M', 'C', 'K', 'E', 'E', 'S', 'R', 'O', 'C', 'K', 'S']\n",
      "['ONE', 'FIVE', 'ONE', 'THREE', 'SIX']\n",
      "['THREE', 'THREE', 'ONE', 'OH', 'ONE', 'EIGHT', 'EIGHT']\n",
      "['TWELVE', 'TWENTY', 'NINE', 'FIFTY', 'NINE']\n",
      "['ENTER', 'NINE', 'TWO', 'EIGHT']\n",
      "['ERASE', 'E', 'D', 'Z', 'E', 'FIFTY', 'SIX']\n",
      "['ENTER', 'EIGHT', 'THIRTEEN']\n",
      "['RUBOUT', 'E', 'Y', 'F', 'C', 'X', 'FOUR']\n",
      "['R', 'H', 'N', 'G', 'A', 'FIFTY', 'FOUR', 'EIGHTY', 'THREE']\n",
      "['P', 'O', 'W', 'E', 'L', 'L']\n",
      "['V', 'A', 'N', 'E', 'S', 'S', 'A']\n",
      "['THREE', 'ZERO', 'TWO', 'ONE']\n",
      "['W', 'I', 'L', 'L', 'E', 'T', 'T']\n",
      "['B', 'R', 'E', 'N', 'T', 'W', 'O', 'O', 'D']\n",
      "['ONE', 'FIVE', 'TWO', 'TWO', 'SEVEN']\n",
      "['EIGHT', 'EIGHT', 'FOUR', 'THREE', 'SIX', 'FOUR', 'EIGHT']\n",
      "['TEN', 'TWENTY', 'SEVEN', 'SIXTY', 'TWO']\n",
      "['RUBOUT', 'N', 'S', 'V', 'H', 'T', 'SIX', 'FORTY', 'NINE']\n",
      "['X', 'N', 'K', 'U', 'EIGHT']\n",
      "['ENTER', 'FOUR', 'FIVE', 'EIGHT', 'TWO', 'ONE']\n",
      "['ERASE', 'P', 'Q', 'Y', 'V', 'T', 'FIVE', 'NINETY', 'EIGHT']\n",
      "['ENTER', 'TWO', 'EIGHTEEN']\n",
      "['H', 'O', 'U', 'S', 'E', 'R']\n",
      "['A', 'L', 'A', 'N']\n",
      "['FIFTY', 'TWO', 'NINETEEN']\n",
      "['C', 'E', 'N', 'T', 'R', 'E']\n",
      "['P', 'I', 'T', 'T', 'S', 'B', 'U', 'R', 'G', 'H']\n",
      "['ONE', 'FIVE', 'TWO', 'THREE', 'TWO']\n",
      "['SIX', 'EIGHT', 'THREE', 'SIX', 'ZERO', 'TWO', 'SEVEN']\n",
      "['MAY', 'SECOND', 'NINETEEN', 'SIXTY', 'FIVE']\n",
      "['ENTER', 'SEVEN', 'ONE', 'FIVE', 'FOUR']\n",
      "['NO']\n",
      "['G', 'F', 'T', 'U', 'ONE', 'THREE', 'THREE', 'TWO']\n",
      "['L', 'K', 'K', 'N', 'THIRTY', 'EIGHT']\n",
      "['RUBOUT', 'V', 'Z', 'J', 'H', 'P', 'SEVEN', 'THIRTY', 'SIX']\n",
      "['S', 'A', 'N', 'D', 'L', 'E', 'R']\n",
      "['D', 'A', 'V', 'I', 'D']\n",
      "['TWO', 'FORTY']\n",
      "['W', 'I', 'L', 'L', 'O', 'W', 'B', 'E', 'N', 'D']\n",
      "['R', 'O', 'C', 'H', 'E', 'S', 'T', 'E', 'R']\n",
      "['ONE', 'FOUR', 'SIX', 'ONE', 'EIGHT']\n",
      "['SEVEN', 'ONE', 'SIX', 'TWO', 'FOUR', 'FOUR', 'SIX', 'SEVEN', 'ONE', 'FOUR']\n",
      "['MARCH', 'SEVEN', 'NINETEEN', 'SIXTY', 'SEVEN']\n",
      "['ENTER', 'TWENTY', 'ONE']\n",
      "['ENTER', 'THIRTY']\n",
      "['D', 'A', 'J', 'N', 'H', 'NINETY', 'SIX']\n",
      "['S', 'Y', 'F', 'C', 'D', 'NINE', 'SIX', 'OH', 'ONE', 'SEVEN']\n",
      "['ENTER', 'ONE', 'SEVENTY', 'SIX']\n",
      "['K', 'A', 'U', 'F', 'M', 'A', 'N']\n",
      "['E', 'R', 'I', 'C']\n",
      "['SIXTY', 'SIX', 'THIRTY', 'THREE']\n",
      "['B', 'I', 'R', 'C', 'H', 'W', 'O', 'O', 'D']\n",
      "['P', 'I', 'T', 'T', 'S', 'B', 'U', 'R', 'G', 'H']\n",
      "['ONE', 'FIVE', 'TWO', 'ONE', 'SEVEN']\n",
      "['FOUR', 'TWO', 'ONE', 'EIGHT', 'EIGHT', 'SIX', 'OH']\n",
      "['FIVE', 'TWENTY', 'SEVEN', 'SIXTY', 'SIX']\n",
      "['ERASE', 'A', 'B', 'F', 'N', 'Q', 'FIFTY', 'SEVEN']\n",
      "['T', 'R', 'T', 'F', 'I', 'SEVEN']\n",
      "['RUBOUT', 'C', 'B', 'W', 'X', 'V', 'FOUR']\n",
      "['W', 'Y', 'A', 'T', 'U', 'SEVENTY', 'SEVEN', 'SEVENTY', 'SEVEN']\n",
      "['ENTER', 'EIGHT']\n",
      "['Y', 'A', 'N', 'A', 'S', 'A', 'K']\n",
      "['I', 'V', 'A', 'N']\n",
      "['TWELVE', 'THIRTY', 'THREE']\n",
      "['M', 'O', 'R', 'E', 'W', 'O', 'O', 'D']\n",
      "['P', 'I', 'T', 'T', 'S', 'B', 'U', 'R', 'G', 'H']\n",
      "['ONE', 'FIVE', 'TWO', 'ONE', 'THREE']\n",
      "['TWO', 'SIX', 'EIGHT', 'FOUR', 'SIX', 'NINE', 'FOUR']\n",
      "['JANUARY', 'SEVENTH', 'NINETEEN', 'SIXTY', 'SEVEN']\n",
      "['ENTER', 'SEVEN']\n",
      "['A', 'B', 'V', 'J', 'NINETY', 'FOUR']\n",
      "['RUBOUT', 'G', 'R', 'A', 'G', 'EIGHTY', 'FIVE']\n",
      "['ENTER', 'FIVE', 'SIX', 'EIGHT']\n",
      "['STOP']\n",
      "['M', 'Y', 'E', 'R', 'S']\n",
      "['J', 'O', 'H', 'N']\n",
      "['TWO', 'TWO', 'SIX']\n",
      "['C', 'E', 'D', 'A', 'R', 'V', 'I', 'L', 'L', 'E']\n",
      "['P', 'I', 'T', 'T', 'S', 'B', 'U', 'R', 'G', 'H']\n",
      "['ONE', 'FIVE', 'TWO', 'TWO', 'FOUR']\n",
      "['SIX', 'EIGHT', 'THREE', 'THREE', 'OH', 'SEVEN', 'FIVE']\n",
      "['NOVEMBER', 'NINTH', 'SIXTY', 'FIVE']\n",
      "['ENTER', 'TWO', 'NINE', 'EIGHT', 'ONE']\n",
      "['REPEAT']\n",
      "['ERASE', 'U', 'D', 'B', 'E', 'FIVE']\n",
      "['RUBOUT', 'U', 'B', 'U', 'T', 'R', 'SIX']\n",
      "['ENTER', 'ONE', 'OH', 'FOUR']\n",
      "['L', 'E', 'V', 'I', 'S', 'O', 'N']\n",
      "['J', 'E', 'F', 'F', 'R', 'E', 'Y']\n",
      "['NINETEEN']\n",
      "['P', 'H', 'I', 'N', 'N', 'E', 'Y']\n",
      "['L', 'E', 'X', 'I', 'N', 'G', 'T', 'O', 'N']\n",
      "['OH', 'TWO', 'ONE', 'SEVEN', 'THREE']\n",
      "['EIGHT', 'SIX', 'TWO', 'OH', 'THREE', 'EIGHT', 'SEVEN']\n",
      "['JUNE', 'EIGHTEENTH', 'NINETEEN', 'SIXTY', 'EIGHT']\n",
      "['X', 'K', 'I', 'T', 'B', 'TWO', 'SIX', 'ONE', 'ONE']\n",
      "['YES']\n",
      "['NO']\n",
      "['ERASE', 'K', 'M', 'H', 'N', 'I', 'SIX', 'OH', 'FIVE']\n",
      "['ERASE', 'F', 'O', 'X', 'K', 'EIGHT']\n",
      "['G', 'I', 'N', 'S', 'B', 'E', 'R', 'G']\n",
      "['M', 'I', 'C', 'H', 'A', 'E', 'L']\n",
      "['A', 'SEVEN']\n",
      "['M', 'A', 'R', 'G', 'A', 'R', 'E', 'T', 'M', 'O', 'R', 'R', 'I', 'S', 'O', 'N']\n",
      "['P', 'I', 'T', 'T', 'S', 'B', 'U', 'R', 'G', 'H']\n",
      "['ONE', 'FIVE', 'TWO', 'ONE', 'THREE']\n",
      "['FOUR', 'ONE', 'TWO', 'TWO', 'SIX', 'EIGHT', 'FOUR', 'ONE', 'FOUR', 'TWO']\n",
      "['OCTOBER', 'TWENTY', 'FOUR', 'NINETEEN', 'SEVENTY']\n"
     ]
    }
   ],
   "source": [
    "with open(test_trans_path, 'r') as f:\n",
    "    transc = f.read().splitlines()\n",
    "    for line in transc:\n",
    "        print(line.split()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 462,
     "status": "ok",
     "timestamp": 1607487851795,
     "user": {
      "displayName": "Shivin Shetty",
      "photoUrl": "",
      "userId": "17836269469119195262"
     },
     "user_tz": 300
    },
    "id": "JjjrKxyuO3K0"
   },
   "outputs": [],
   "source": [
    "def make_sent_graph(word_list, calc_grad=True, blank=0):\n",
    "    interleaved_list = ['<s>']\n",
    "    for word in word_list:\n",
    "        interleaved_list.append(word)\n",
    "        interleaved_list.append('<sil>')\n",
    "    interleaved_list = interleaved_list[:-1]\n",
    "    interleaved_list.append('</s>')\n",
    "    graphs = [make_word_graph(wrd, calc_grad, blank) for wrd in interleaved_list]\n",
    "    return gtn.concat(graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "erWX6AWZO3K1"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1607487853294,
     "user": {
      "displayName": "Shivin Shetty",
      "photoUrl": "",
      "userId": "17836269469119195262"
     },
     "user_tz": 300
    },
    "id": "lL7uLPNzO3K1"
   },
   "outputs": [],
   "source": [
    "kernel_size = 100\n",
    "stride = 50\n",
    "padding = 0\n",
    "\n",
    "def get_conv_out_size(in_len):\n",
    "    return ((in_len - kernel_size) // stride) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 413,
     "status": "ok",
     "timestamp": 1607487854210,
     "user": {
      "displayName": "Shivin Shetty",
      "photoUrl": "",
      "userId": "17836269469119195262"
     },
     "user_tz": 300
    },
    "id": "OXT2_xa0O3K1"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, fileids_path, trans_path, end_marked=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        with open(fileids_path, 'r') as f:\n",
    "            self.audio_files = f.read().splitlines()\n",
    "        with open(trans_path, 'r') as f:\n",
    "            transc = f.read().splitlines()   \n",
    "            self.trans_graphs = []\n",
    "            for line in transc:\n",
    "                # make the corresponding graph\n",
    "                transcription = line.split()[:-1]\n",
    "                if end_marked:\n",
    "                    transcription = transcription[1:-1]\n",
    "                self.trans_graphs.append(make_sent_graph(transcription))\n",
    "        self.len = len(self.audio_files)\n",
    "        assert(self.len == len(self.trans_graphs))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        full_audio_path = wav_path + self.audio_files[ind] + \".sph\"\n",
    "        audio_tensor = torch.FloatTensor(sf.read(full_audio_path)[0]).unsqueeze(1)\n",
    "        audio_tensor_len = get_conv_out_size(audio_tensor.shape[0])\n",
    "#         print(audio_tensor.shape, audio_tensor_len)\n",
    "        return audio_tensor, audio_tensor_len, ind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "HVKFLrSxO3K1"
   },
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_fileids_path, train_trans_path, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1607487859679,
     "user": {
      "displayName": "Shivin Shetty",
      "photoUrl": "",
      "userId": "17836269469119195262"
     },
     "user_tz": 300
    },
    "id": "HtgL6swOO3K2",
    "outputId": "d3158b47-17ed-4c5b-c912-1a839bf637a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "print(cuda)\n",
    "num_workers = 8 if cuda else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1607487860805,
     "user": {
      "displayName": "Shivin Shetty",
      "photoUrl": "",
      "userId": "17836269469119195262"
     },
     "user_tz": 300
    },
    "id": "0HjhJlgMO3K2"
   },
   "outputs": [],
   "source": [
    "class MyBatch:\n",
    "    def __init__(self, data):\n",
    "        zipped = list(zip(*data))\n",
    "#         print([i.shape for i in zipped[0]])\n",
    "#         print([a.shape for a in zipped[0]])\n",
    "        self.X = pad_sequence(zipped[0])\n",
    "#         print(self.X.shape, [a.shape for a in zipped[0]])\n",
    "        self.X_len = torch.LongTensor(zipped[1])\n",
    "#         self.Y = pad_sequence(zipped[2], batch_first=True)\n",
    "#         self.Y_len = torch.LongTensor(zipped[3])\n",
    "        self.Y = torch.LongTensor(zipped[2])\n",
    "\n",
    "    def pin_memory(self):\n",
    "        self.X = self.X.pin_memory()\n",
    "        self.X_len = self.X_len.pin_memory()\n",
    "        self.Y = self.Y.pin_memory()\n",
    "        return self\n",
    "\n",
    "def collate_wrapper(batch):\n",
    "    return MyBatch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 332,
     "status": "ok",
     "timestamp": 1607487861645,
     "user": {
      "displayName": "Shivin Shetty",
      "photoUrl": "",
      "userId": "17836269469119195262"
     },
     "user_tz": 300
    },
    "id": "xWGr9DY1O3K2"
   },
   "outputs": [],
   "source": [
    "train_loader_args = dict(shuffle=True, batch_size=batch_size,\n",
    "                            num_workers=num_workers, pin_memory=False, drop_last=True, collate_fn=collate_wrapper) if cuda\\\n",
    "                    else dict(shuffle=True, batch_size=batch_size, collate_fn=collate_wrapper)\n",
    "train_loader = data.DataLoader(train_dataset, **train_loader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 332,
     "status": "ok",
     "timestamp": 1607487861645,
     "user": {
      "displayName": "Shivin Shetty",
      "photoUrl": "",
      "userId": "17836269469119195262"
     },
     "user_tz": 300
    },
    "id": "xWGr9DY1O3K2"
   },
   "outputs": [],
   "source": [
    "test_dataset = MyDataset(test_fileids_path, test_trans_path, True)\n",
    "test_loader_args = dict(shuffle=False, batch_size=batch_size,\n",
    "                            num_workers=num_workers, pin_memory=False, drop_last=True, collate_fn=collate_wrapper) if cuda\\\n",
    "                    else dict(shuffle=False, batch_size=batch_size, collate_fn=collate_wrapper)\n",
    "test_loader = data.DataLoader(test_dataset, **test_loader_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WwSf1K_qO3K2"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "executionInfo": {
     "elapsed": 432,
     "status": "ok",
     "timestamp": 1607487862976,
     "user": {
      "displayName": "Shivin Shetty",
      "photoUrl": "",
      "userId": "17836269469119195262"
     },
     "user_tz": 300
    },
    "id": "2sURCwnyO3K2"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_vocab, out_vocab, embed_size, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.cnn = nn.Conv1d(1, 5, kernel_size, stride=stride, padding=padding)\n",
    "        self.bn = nn.BatchNorm1d(5)\n",
    "        self.relu = F.relu\n",
    "\n",
    "        self.lstm = nn.LSTM(5, hidden_size, num_layers=2, bidirectional=True, batch_first=False)\n",
    "        self.output = nn.Linear(hidden_size*2, out_vocab)\n",
    "        self.lsm = nn.LogSoftmax(2)\n",
    "    \n",
    "    def forward(self, X, lengths):\n",
    "        X_t = X.permute(1,2,0)\n",
    "        cnn_xt = self.cnn(X_t)\n",
    "        cnn_xt = self.bn(cnn_xt)\n",
    "        cnn_xt = self.relu(cnn_xt)\n",
    "        cnn_x = cnn_xt.permute(2,0,1)\n",
    "        \n",
    "        packed_X = pack_padded_sequence(cnn_x, lengths, enforce_sorted=False)\n",
    "        packed_out = self.lstm(packed_X)[0]\n",
    "        out, out_lens = pad_packed_sequence(packed_out)\n",
    "        out = self.output(out)\n",
    "        out = self.lsm(out)\n",
    "        return out, out_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "executionInfo": {
     "elapsed": 404,
     "status": "ok",
     "timestamp": 1607487867108,
     "user": {
      "displayName": "Shivin Shetty",
      "photoUrl": "",
      "userId": "17836269469119195262"
     },
     "user_tz": 300
    },
    "id": "jYzgP-LNO3K3"
   },
   "outputs": [],
   "source": [
    "class GTNLossFunction(torch.autograd.Function):\n",
    "        \n",
    "    @staticmethod\n",
    "    def forward(ctx, inputs, input_lengths, targets): #targets is index in trans_graph\n",
    "        _, B, _ = inputs.shape\n",
    "        losses = [None] * B\n",
    "        emissions_graphs = [None] * B\n",
    "    \n",
    "        def forward_single(b):\n",
    "            T = input_lengths[b]\n",
    "            weights = torch.clamp(inputs[:T, b, :], min=-1e-20).flatten().contiguous()\n",
    "            flat_weights = weights.data_ptr()\n",
    "            \n",
    "            ind = targets[b]\n",
    "\n",
    "            emit = gtn.linear_graph(T, num_phones, inputs.requires_grad)\n",
    "            emit.set_weights(flat_weights) # set in the same order as the phoneme order\n",
    "\n",
    "            constraint = train_dataset.trans_graphs[ind]\n",
    "\n",
    "            alignment = gtn.compose(constraint, emit)\n",
    "            ctc_loss = gtn.subtract(gtn.forward_score(emit), gtn.forward_score(alignment))\n",
    "\n",
    "            losses[b] = ctc_loss\n",
    "            emissions_graphs[b] = emit\n",
    "\n",
    "        gtn.parallel_for(forward_single, range(B))\n",
    "\n",
    "        ctx.auxiliary_data = (losses, emissions_graphs, inputs.shape, input_lengths, targets)\n",
    "        \n",
    "        retval = torch.tensor([l.item() for l in losses])\n",
    "        return retval\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output, retain_graph=True):\n",
    "        losses, emissions_graphs, in_shape, input_lengths, targets = ctx.auxiliary_data\n",
    "        T, B, C = in_shape\n",
    "        input_grad = torch.empty((T, B, C))\n",
    "\n",
    "        def backward_single(b):\n",
    "            gtn.backward(losses[b], retain_graph=retain_graph)\n",
    "            emissions = emissions_graphs[b]\n",
    "            grad = emissions.grad().weights_to_numpy()\n",
    "            input_grad[:int(input_lengths[b].detach()),b,:] = torch.from_numpy(grad).view(\n",
    "                                                                int(input_lengths[b].detach()), C)\n",
    "            train_dataset.trans_graphs[targets[b]].zero_grad()\n",
    "\n",
    "\n",
    "        gtn.parallel_for(backward_single, range(B))\n",
    "        return input_grad, None, None\n",
    "\n",
    "# make an alias for the loss function:\n",
    "GTNLoss = GTNLossFunction.apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    for batch_ids, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x = batch.X.to(device)\n",
    "        x_len = batch.X_len.to(device)\n",
    "        y = batch.Y\n",
    "        out, out_lens = model(x, x_len)\n",
    "        out = out.to(\"cpu\")\n",
    "        out_lens = out_lens.to(\"cpu\")\n",
    "        loss = criterion(out, out_lens, y).mean()\n",
    "        print(\"batch:\", batch_ids, \"loss\", loss.item())\n",
    "        running_loss += loss.item()\n",
    "        loss.backward(retain_graph=False)\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "    end_time = time.time()\n",
    "    \n",
    "    running_loss /= len(train_loader)\n",
    "    \n",
    "    print(\"Training Loss: \", running_loss, \"Time: \", end_time - start_time, \"s\")\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, criterion):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            X = batch.X.to(device)\n",
    "            X_len = batch.X_len.to(device)\n",
    "            Y = batch.Y\n",
    "            \n",
    "            out, out_lens = model(X, X_len)\n",
    "            out = out.to(\"cpu\")\n",
    "            out_lens = out_lens.to(\"cpu\")\n",
    "\n",
    "            loss = criterion(out, out_lens, Y).mean()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        running_loss /= len(test_loader)\n",
    "        print(\"Testing Loss: \", running_loss)\n",
    "        return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 363,
     "status": "ok",
     "timestamp": 1607487869507,
     "user": {
      "displayName": "Shivin Shetty",
      "photoUrl": "",
      "userId": "17836269469119195262"
     },
     "user_tz": 300
    },
    "id": "Be3SDSTLO3K4",
    "outputId": "de78a66b-94ee-486b-f699-fa24a4305ac8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (cnn): Conv1d(1, 5, kernel_size=(100,), stride=(50,))\n",
      "  (bn): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (lstm): LSTM(5, 50, num_layers=2, bidirectional=True)\n",
      "  (output): Linear(in_features=100, out_features=35, bias=True)\n",
      "  (lsm): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(32)\n",
    "model = Model(40, num_phones, 5, 50)\n",
    "criterion = GTNLoss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1\n",
    "                           )\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0 loss 2855.896728515625\n",
      "batch: 1 loss 3096.24658203125\n",
      "batch: 2 loss 3302.682373046875\n",
      "batch: 3 loss 2775.615234375\n",
      "batch: 4 loss 3078.640869140625\n",
      "batch: 5 loss 2957.93115234375\n",
      "batch: 6 loss 2454.426513671875\n",
      "batch: 7 loss 2680.68994140625\n",
      "batch: 8 loss 2464.47607421875\n",
      "batch: 9 loss 3280.743408203125\n",
      "batch: 10 loss 2879.221923828125\n",
      "batch: 11 loss 3005.934814453125\n",
      "batch: 12 loss 2687.364501953125\n",
      "batch: 13 loss 2483.84716796875\n",
      "batch: 14 loss 2571.17919921875\n",
      "batch: 15 loss 2900.325439453125\n",
      "batch: 16 loss 3227.47509765625\n",
      "batch: 17 loss 2280.962158203125\n",
      "batch: 18 loss 3034.94921875\n",
      "batch: 19 loss 2818.93408203125\n",
      "batch: 20 loss 2659.01904296875\n",
      "batch: 21 loss 2890.999755859375\n",
      "batch: 22 loss 2499.42138671875\n",
      "batch: 23 loss 2743.695068359375\n",
      "batch: 24 loss 3134.795654296875\n",
      "batch: 25 loss 3098.53076171875\n",
      "batch: 26 loss 3130.005859375\n",
      "batch: 27 loss 2535.150146484375\n",
      "batch: 28 loss 2206.78564453125\n",
      "batch: 29 loss 3119.938232421875\n",
      "batch: 30 loss 2510.900634765625\n",
      "batch: 31 loss 2816.305908203125\n",
      "batch: 32 loss 2762.29931640625\n",
      "batch: 33 loss 2897.867919921875\n",
      "batch: 34 loss 2984.49853515625\n",
      "batch: 35 loss 2762.71240234375\n",
      "batch: 36 loss 2770.2958984375\n",
      "batch: 37 loss 2817.248291015625\n",
      "batch: 38 loss 2644.36181640625\n",
      "batch: 39 loss 2820.52392578125\n",
      "batch: 40 loss 3181.536376953125\n",
      "batch: 41 loss 3041.482666015625\n",
      "batch: 42 loss 2740.59130859375\n",
      "batch: 43 loss 3145.24658203125\n",
      "batch: 44 loss 3511.130859375\n",
      "batch: 45 loss 2916.212158203125\n",
      "batch: 46 loss 2780.111083984375\n",
      "Training Loss:  2850.19595142121 Time:  46.683252811431885 s\n",
      "Testing Loss:  2897.198771158854\n",
      "=====End of Epoch 0 =====\n",
      "batch: 0 loss 2780.6630859375\n",
      "batch: 1 loss 3073.462158203125\n",
      "batch: 2 loss 3177.626708984375\n",
      "batch: 3 loss 2681.004150390625\n",
      "batch: 4 loss 2399.730712890625\n",
      "batch: 5 loss 2289.84033203125\n",
      "batch: 6 loss 2820.034423828125\n",
      "batch: 7 loss 2954.44384765625\n",
      "batch: 8 loss 2899.1572265625\n",
      "batch: 9 loss 2960.253662109375\n",
      "batch: 10 loss 2526.038818359375\n",
      "batch: 11 loss 2685.755615234375\n",
      "batch: 12 loss 2525.619140625\n",
      "batch: 13 loss 2892.53125\n",
      "batch: 14 loss 2942.74462890625\n",
      "batch: 15 loss 2951.20361328125\n",
      "batch: 16 loss 3122.423828125\n",
      "batch: 17 loss 2563.17041015625\n",
      "batch: 18 loss 2552.7392578125\n",
      "batch: 19 loss 2950.644775390625\n",
      "batch: 20 loss 2710.241943359375\n",
      "batch: 21 loss 2812.36181640625\n",
      "batch: 22 loss 3051.2333984375\n",
      "batch: 23 loss 2999.949462890625\n",
      "batch: 24 loss 2605.323974609375\n",
      "batch: 25 loss 2981.875732421875\n",
      "batch: 26 loss 3430.556640625\n",
      "batch: 27 loss 2529.20068359375\n",
      "batch: 28 loss 2667.03955078125\n",
      "batch: 29 loss 3176.243408203125\n",
      "batch: 30 loss 2863.42919921875\n",
      "batch: 31 loss 2521.73876953125\n",
      "batch: 32 loss 2604.58837890625\n",
      "batch: 33 loss 2897.96142578125\n",
      "batch: 34 loss 2562.73583984375\n",
      "batch: 35 loss 3371.181640625\n",
      "batch: 36 loss 3702.87109375\n",
      "batch: 37 loss 2995.82177734375\n",
      "batch: 38 loss 3151.593505859375\n",
      "batch: 39 loss 3375.47021484375\n",
      "batch: 40 loss 2405.18994140625\n",
      "batch: 41 loss 3285.225830078125\n",
      "batch: 42 loss 3082.063720703125\n",
      "batch: 43 loss 2380.209716796875\n",
      "batch: 44 loss 2724.388916015625\n",
      "batch: 45 loss 2682.86181640625\n",
      "batch: 46 loss 2583.6923828125\n",
      "Training Loss:  2849.024221866689 Time:  46.865089893341064 s\n",
      "Testing Loss:  2897.198771158854\n",
      "=====End of Epoch 1 =====\n",
      "batch: 0 loss 3148.498046875\n",
      "batch: 1 loss 2444.27392578125\n",
      "batch: 2 loss 3190.43603515625\n",
      "batch: 3 loss 2961.15966796875\n",
      "batch: 4 loss 2398.47509765625\n",
      "batch: 5 loss 3282.474609375\n",
      "batch: 6 loss 2682.409912109375\n",
      "batch: 7 loss 3067.037841796875\n",
      "batch: 8 loss 2749.135498046875\n",
      "batch: 9 loss 2678.05029296875\n",
      "batch: 10 loss 2947.100341796875\n",
      "batch: 11 loss 2851.414306640625\n",
      "batch: 12 loss 2773.840087890625\n",
      "batch: 13 loss 2883.580810546875\n",
      "batch: 14 loss 2534.459228515625\n",
      "batch: 15 loss 2641.482177734375\n",
      "batch: 16 loss 2938.32568359375\n",
      "batch: 17 loss 3102.157470703125\n",
      "batch: 18 loss 2799.86474609375\n",
      "batch: 19 loss 2387.1396484375\n",
      "batch: 20 loss 2498.924072265625\n",
      "batch: 21 loss 2418.049072265625\n",
      "batch: 22 loss 3017.814453125\n",
      "batch: 23 loss 3224.34521484375\n",
      "batch: 24 loss 3182.785888671875\n",
      "batch: 25 loss 2831.599609375\n",
      "batch: 26 loss 3130.813232421875\n",
      "batch: 27 loss 2727.82373046875\n",
      "batch: 28 loss 2472.57421875\n",
      "batch: 29 loss 3166.6806640625\n",
      "batch: 30 loss 2951.778564453125\n",
      "batch: 31 loss 2648.676513671875\n",
      "batch: 32 loss 2678.31982421875\n",
      "batch: 33 loss 2987.58203125\n",
      "batch: 34 loss 2846.787353515625\n",
      "batch: 35 loss 3027.17724609375\n",
      "batch: 36 loss 2959.17138671875\n",
      "batch: 37 loss 2889.29541015625\n",
      "batch: 38 loss 2868.146728515625\n",
      "batch: 39 loss 2534.468017578125\n",
      "batch: 40 loss 2845.345947265625\n",
      "batch: 41 loss 3269.06787109375\n",
      "batch: 42 loss 2729.549072265625\n",
      "batch: 43 loss 2661.687255859375\n",
      "batch: 44 loss 2633.25341796875\n",
      "batch: 45 loss 3109.30322265625\n",
      "batch: 46 loss 2990.26123046875\n",
      "Training Loss:  2846.0126953125 Time:  48.07799673080444 s\n",
      "Testing Loss:  2897.198771158854\n",
      "=====End of Epoch 2 =====\n",
      "batch: 0 loss 3390.37060546875\n",
      "batch: 1 loss 2515.748779296875\n",
      "batch: 2 loss 2818.31005859375\n",
      "batch: 3 loss 2935.96630859375\n",
      "batch: 4 loss 3151.22412109375\n",
      "batch: 5 loss 2775.81982421875\n",
      "batch: 6 loss 2844.01171875\n",
      "batch: 7 loss 2568.87158203125\n",
      "batch: 8 loss 3414.57861328125\n",
      "batch: 9 loss 2813.76806640625\n",
      "batch: 10 loss 2445.64013671875\n",
      "batch: 11 loss 3233.755126953125\n",
      "batch: 12 loss 3238.87646484375\n",
      "batch: 13 loss 2743.966796875\n",
      "batch: 14 loss 2829.738037109375\n",
      "batch: 15 loss 2986.845703125\n",
      "batch: 16 loss 2475.9462890625\n",
      "batch: 17 loss 2555.652587890625\n",
      "batch: 18 loss 2675.51611328125\n",
      "batch: 19 loss 2786.19287109375\n",
      "batch: 20 loss 2691.265625\n",
      "batch: 21 loss 2303.455322265625\n",
      "batch: 22 loss 2552.346923828125\n",
      "batch: 23 loss 2511.591796875\n",
      "batch: 24 loss 2976.85498046875\n",
      "batch: 25 loss 2694.053466796875\n",
      "batch: 26 loss 3081.385498046875\n",
      "batch: 27 loss 3197.256591796875\n",
      "batch: 28 loss 3382.90673828125\n",
      "batch: 29 loss 3302.48974609375\n",
      "batch: 30 loss 3570.610595703125\n",
      "batch: 31 loss 3008.63916015625\n",
      "batch: 32 loss 2721.6201171875\n",
      "batch: 33 loss 2841.0625\n",
      "batch: 34 loss 2771.898681640625\n",
      "batch: 35 loss 2730.39794921875\n",
      "batch: 36 loss 2638.697998046875\n",
      "batch: 37 loss 2992.66064453125\n",
      "batch: 38 loss 2786.314453125\n",
      "batch: 39 loss 2396.666259765625\n",
      "batch: 40 loss 2628.701904296875\n",
      "batch: 41 loss 2802.05126953125\n",
      "batch: 42 loss 2628.088134765625\n",
      "batch: 43 loss 2720.032470703125\n",
      "batch: 44 loss 3124.498046875\n",
      "batch: 45 loss 3169.89013671875\n",
      "batch: 46 loss 2516.10546875\n",
      "Training Loss:  2849.8370698969416 Time:  47.02353549003601 s\n",
      "Testing Loss:  2897.198771158854\n",
      "=====End of Epoch 3 =====\n",
      "batch: 0 loss 3057.55712890625\n",
      "batch: 1 loss 2671.94677734375\n",
      "batch: 2 loss 2467.741455078125\n",
      "batch: 3 loss 3219.67724609375\n",
      "batch: 4 loss 2660.19775390625\n",
      "batch: 5 loss 2669.62255859375\n",
      "batch: 6 loss 2710.6064453125\n",
      "batch: 7 loss 2532.039306640625\n",
      "batch: 8 loss 3172.158447265625\n",
      "batch: 9 loss 2896.3046875\n",
      "batch: 10 loss 2703.22900390625\n",
      "batch: 11 loss 3024.195068359375\n",
      "batch: 12 loss 2774.302001953125\n",
      "batch: 13 loss 2361.22119140625\n",
      "batch: 14 loss 2916.288330078125\n",
      "batch: 15 loss 2459.005859375\n",
      "batch: 16 loss 2595.119873046875\n",
      "batch: 17 loss 2815.12158203125\n",
      "batch: 18 loss 2990.28857421875\n",
      "batch: 19 loss 2700.29638671875\n",
      "batch: 20 loss 2942.078125\n",
      "batch: 21 loss 3260.713623046875\n",
      "batch: 22 loss 2943.01318359375\n",
      "batch: 23 loss 2824.79345703125\n",
      "batch: 24 loss 2922.2724609375\n",
      "batch: 25 loss 2442.9013671875\n",
      "batch: 26 loss 3052.78955078125\n",
      "batch: 27 loss 3166.0546875\n",
      "batch: 28 loss 3413.42236328125\n",
      "batch: 29 loss 2511.42822265625\n",
      "batch: 30 loss 3107.511474609375\n",
      "batch: 31 loss 2598.66748046875\n",
      "batch: 32 loss 3043.93017578125\n",
      "batch: 33 loss 2588.031005859375\n",
      "batch: 34 loss 3217.52001953125\n",
      "batch: 35 loss 2836.52490234375\n",
      "batch: 36 loss 3059.18701171875\n",
      "batch: 37 loss 3162.830322265625\n",
      "batch: 38 loss 3317.315185546875\n",
      "batch: 39 loss 2900.677978515625\n",
      "batch: 40 loss 2701.08251953125\n",
      "batch: 41 loss 2163.218505859375\n",
      "batch: 42 loss 3230.09521484375\n",
      "batch: 43 loss 2934.60986328125\n",
      "batch: 44 loss 2505.7412109375\n",
      "batch: 45 loss 2629.09716796875\n",
      "batch: 46 loss 3124.40283203125\n",
      "Training Loss:  2850.996374251995 Time:  47.370156049728394 s\n",
      "Testing Loss:  2897.198771158854\n",
      "=====End of Epoch 4 =====\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "training_losses = []\n",
    "testing_losses = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    torch.save({'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "               }, \"Model_\"+str(i))\n",
    "    \n",
    "    test_loss = test_model(model, test_loader, criterion)\n",
    "    training_losses.append(train_loss)\n",
    "    testing_losses.append(test_loss)\n",
    "#     for name, param in model.named_parameters():\n",
    "#         if param.requires_grad:\n",
    "#             print(name, param.data)\n",
    "    print(\"=====End of Epoch\", i, \"=====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_model(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            X = batch.X.to(device)\n",
    "            X_len = batch.X_len.to(device)\n",
    "            Y = batch.Y\n",
    "            \n",
    "            out, out_lens = model(X, X_len)\n",
    "            out = out.to(\"cpu\")\n",
    "            out_lens = out_lens.to(\"cpu\")\n",
    "            \n",
    "            for b in range(batch_size):\n",
    "                print(b)\n",
    "                T = out_lens[b]\n",
    "                weights = out[:T, b, :].flatten().contiguous()\n",
    "                flat_weights = weights.data_ptr()\n",
    "\n",
    "                ind = Y[b]\n",
    "\n",
    "                emit = gtn.linear_graph(T, num_phones, out.requires_grad)\n",
    "                emit.set_weights(flat_weights)\n",
    "                prediction = gtn.viterbi_path(emit).labels_to_list(False)\n",
    "                print(prediction)\n",
    "                break  \n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n"
     ]
    }
   ],
   "source": [
    "decode_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ctc.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
